{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part I: Prepare our weather training data for the models</h1>\n",
    "<ul>\n",
    "    <li>Need to strip the data for each city in each data set and combine them all into onedataset</li>\n",
    "    <li>Need to also get the data for each city's latitude and longitude and include that in the dataset for predicting the forecasts</li>\n",
    "    <li>Need to prepare labels so that they are offest one hour</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 1: Load data from csv files<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-20c6e3263db8>:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.test.is_built_with_cuda()\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_weather_data(csv_file):\n",
    "    city_attrib_csv_path = \"datasets/historical-hourly-weather-data/\" + csv_file\n",
    "    return pd.read_csv(city_attrib_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_attributes_csv = load_weather_data(\"city_attributes.csv\")\n",
    "humidity_csv = load_weather_data(\"humidity.csv\")\n",
    "pressure_csv = load_weather_data(\"pressure.csv\")\n",
    "temperature_csv = load_weather_data(\"temperature.csv\")\n",
    "weather_description_csv = load_weather_data(\"weather_description.csv\")\n",
    "wind_direction_csv = load_weather_data(\"wind_direction.csv\")\n",
    "wind_speed_csv = load_weather_data(\"wind_speed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 2: Load the datasets for each city</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_city_dataset(city_name, model_labels_name):\n",
    "    city_dataset = pd.DataFrame(data=humidity_csv[\"datetime\"])\n",
    "    \n",
    "    # create new columns for month, day, hour_of_day\n",
    "    # this will be used to split up data in \"datatime\" column\n",
    "    city_dataset[\"month\"] = \"\"\n",
    "    city_dataset[\"day\"] = \"\"\n",
    "    city_dataset[\"hour_of_day\"] = \"\"\n",
    "    \n",
    "    # seperate the values for datetime into month, day, hour_of_day int columns\n",
    "    for i, date in enumerate(city_dataset[\"datetime\"]):\n",
    "        date, time = date.split(\" \", 1)\n",
    "        year, month, day = date.split(\"-\", 2)\n",
    "        hours, minute_seconds = time.split(\":\", 1)\n",
    "        \n",
    "        city_dataset[\"month\"][i] = int(month)\n",
    "        city_dataset[\"day\"][i] = int(day)\n",
    "        city_dataset[\"hour_of_day\"][i] = int(hours)\n",
    "\n",
    "    # drop datetime column\n",
    "    city_dataset = city_dataset.drop(\"datetime\", axis=1)\n",
    "        \n",
    "    # create new columns for latitude and longitude\n",
    "    # add the values to each row in the table\n",
    "    city_dataset[\"latitude\"] = \"\"\n",
    "    city_dataset[\"longitude\"] = \"\"\n",
    "    city_index = city_attributes_csv.index[city_attributes_csv[\"City\"] == city_name]\n",
    "    latitude_val = city_attributes_csv.get_value(city_index[0], \"Latitude\")\n",
    "    longitude_val = city_attributes_csv.get_value(city_index[0], \"Longitude\")\n",
    "    \n",
    "    for i, row in enumerate(city_dataset[\"day\"]):\n",
    "        city_dataset[\"latitude\"][i] = latitude_val\n",
    "        city_dataset[\"longitude\"][i] = longitude_val\n",
    "    \n",
    "    # create new columns\n",
    "    # assign weather data for the city to columns\n",
    "    city_dataset[\"humidity\"] = humidity_csv[city_name]\n",
    "    city_dataset[\"pressure\"] = pressure_csv[city_name]\n",
    "    city_dataset[\"temperature\"] = temperature_csv[city_name]\n",
    "    city_dataset[\"weather_description\"] = weather_description_csv[city_name]\n",
    "    city_dataset[\"wind_direction\"] = wind_direction_csv[city_name]\n",
    "    city_dataset[\"wind_speed\"] = wind_speed_csv[city_name]\n",
    "    \n",
    "    # create new column for labels\n",
    "    # each label represents the value of an attribute one hour later\n",
    "    city_dataset[model_labels_name + \"_labels\"] = \"\"\n",
    "    for i, row in enumerate(city_dataset[model_labels_name]):\n",
    "        if(i < (len(city_dataset.index) - 1)):\n",
    "            city_dataset[model_labels_name + \"_labels\"][i] = city_dataset[model_labels_name][i + 1]\n",
    "        else:\n",
    "            city_dataset[model_labels_name + \"_labels\"][i] = np.NaN\n",
    "            \n",
    "    return city_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 3: Combine all of the cities into one dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_cities(city_att_file, model_labels_name):\n",
    "    # create new dataset to hold all of the weather data\n",
    "    full_dataset = pd.DataFrame()\n",
    "    \n",
    "    # load data for each city and append to the full dataframe set\n",
    "    for city in city_att_file[\"City\"]:\n",
    "        full_dataset = full_dataset.append(load_city_dataset(city, model_labels_name))\n",
    "    \n",
    "    # re-index the dataframe\n",
    "    full_dataset = full_dataset.reset_index()\n",
    "    full_dataset = full_dataset.drop(columns=['index'])\n",
    "    \n",
    "    return(full_dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "full_humidity_dataset = combine_all_cities(city_attributes_csv, model_labels_name=\"humidity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>humidity_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>49.2497</td>\n",
       "      <td>-123.119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>49.2497</td>\n",
       "      <td>-123.119</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284.630000</td>\n",
       "      <td>mist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>49.2497</td>\n",
       "      <td>-123.119</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284.629041</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>49.2497</td>\n",
       "      <td>-123.119</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284.626998</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>49.2497</td>\n",
       "      <td>-123.119</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284.624955</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629103</th>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>31.769</td>\n",
       "      <td>35.2163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629104</th>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>31.769</td>\n",
       "      <td>35.2163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629105</th>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>31.769</td>\n",
       "      <td>35.2163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629106</th>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>31.769</td>\n",
       "      <td>35.2163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629107</th>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>31.769</td>\n",
       "      <td>35.2163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1629108 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        month day hour_of_day latitude longitude  humidity  pressure  \\\n",
       "0          10   1          12  49.2497  -123.119       NaN       NaN   \n",
       "1          10   1          13  49.2497  -123.119      76.0       NaN   \n",
       "2          10   1          14  49.2497  -123.119      76.0       NaN   \n",
       "3          10   1          15  49.2497  -123.119      76.0       NaN   \n",
       "4          10   1          16  49.2497  -123.119      77.0       NaN   \n",
       "...       ...  ..         ...      ...       ...       ...       ...   \n",
       "1629103    11  29          20   31.769   35.2163       NaN       NaN   \n",
       "1629104    11  29          21   31.769   35.2163       NaN       NaN   \n",
       "1629105    11  29          22   31.769   35.2163       NaN       NaN   \n",
       "1629106    11  29          23   31.769   35.2163       NaN       NaN   \n",
       "1629107    11  30           0   31.769   35.2163       NaN       NaN   \n",
       "\n",
       "         temperature weather_description  wind_direction  wind_speed  \\\n",
       "0                NaN                 NaN             NaN         NaN   \n",
       "1         284.630000                mist             0.0         0.0   \n",
       "2         284.629041       broken clouds             6.0         0.0   \n",
       "3         284.626998       broken clouds            20.0         0.0   \n",
       "4         284.624955       broken clouds            34.0         0.0   \n",
       "...              ...                 ...             ...         ...   \n",
       "1629103          NaN                 NaN             NaN         NaN   \n",
       "1629104          NaN                 NaN             NaN         NaN   \n",
       "1629105          NaN                 NaN             NaN         NaN   \n",
       "1629106          NaN                 NaN             NaN         NaN   \n",
       "1629107          NaN                 NaN             NaN         NaN   \n",
       "\n",
       "        humidity_labels  \n",
       "0                    76  \n",
       "1                    76  \n",
       "2                    76  \n",
       "3                    77  \n",
       "4                    78  \n",
       "...                 ...  \n",
       "1629103             NaN  \n",
       "1629104             NaN  \n",
       "1629105             NaN  \n",
       "1629106             NaN  \n",
       "1629107             NaN  \n",
       "\n",
       "[1629108 rows x 12 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_humidity_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataset as csv for easy import on other projects\n",
    "full_humidity_dataset.to_csv('weather_data_with_humidity_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "full_pressure_dataset = combine_all_cities(city_attributes_csv, model_labels_name=\"pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pressure_dataset.to_csv('weather_data_with_pressure_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "full_temperature_dataset = combine_all_cities(city_attributes_csv, model_labels_name=\"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temperature_dataset.to_csv('weather_data_with_temperature_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "full_description_dataset = combine_all_cities(city_attributes_csv, \n",
    "                                              model_labels_name=\"weather_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_description_dataset.to_csv('weather_data_with_description_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "full_wdirection_dataset = combine_all_cities(city_attributes_csv,\n",
    "                                            model_labels_name=\"wind_direction\")\n",
    "full_wdirection_dataset.to_csv('weather_data_with_wdirection_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_wdirection_dataset.to_csv('weather_data_with_wdirection_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "full_wspeed_dataset = combine_all_cities(city_attributes_csv,\n",
    "                                        model_labels_name=\"wind_speed\")\n",
    "full_wspeed_dataset.to_csv('weather_data_with_wspeed_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_wspeed_dataset.to_csv('weather_data_with_wspeed_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 4: Clean the full dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temperature_dataset = load_weather_data('weather_data_with_temperature_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temperature_dataset = full_temperature_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temperature_dataset = full_temperature_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pressure_dataset = load_weather_data('weather_data_with_pressure_labels.csv')\n",
    "full_pressure_dataset = full_pressure_dataset.dropna()\n",
    "full_pressure_dataset = full_pressure_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 5: Transformer pipeline </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numbers_pipe = Pipeline([\n",
    "     ('std_scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = full_temperature_dataset.drop(\"weather_description\", axis=1)\n",
    "train_num = train_num.drop(\"temperature_labels\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = full_pressure_dataset.drop(\"weather_description\", axis=1)\n",
    "train_num = train_num.drop(\"pressure_labels\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "num_attribs = list(train_num)\n",
    "cat_attribs = [\"weather_description\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", numbers_pipe, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 6: Split the data into a training and testing set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_labels = full_temperature_dataset[['temperature_labels']]\n",
    "temperature_data = full_temperature_dataset.drop(columns=['temperature_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = full_pressure_dataset[['pressure_labels']]\n",
    "data = full_pressure_dataset.drop(columns=['pressure_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('num',\n",
       "                                 Pipeline(memory=None,\n",
       "                                          steps=[('std_scaler',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True))],\n",
       "                                          verbose=False),\n",
       "                                 ['month', 'day', 'hour_of_day', 'latitude',\n",
       "                                  'longitude', 'humidity', 'pressure',\n",
       "                                  'temperature', 'wind_direction',\n",
       "                                  'wind_speed']),\n",
       "                                ('cat',\n",
       "                                 OneHotEncoder(categories='auto', drop=None,\n",
       "                                               dtype=<class 'numpy.float64'>,\n",
       "                                               handle_unknown='error',\n",
       "                                               sparse=True),\n",
       "                                 ['weather_description'])],\n",
       "                  verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "full_training_data, test_data, full_training_labels, test_labels = train_test_split(\n",
    "    data, labels)\n",
    "training_data, valid_data, training_labels, valid_labels = train_test_split(\n",
    "    full_training_data, full_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = full_pipeline.transform(training_data).toarray()\n",
    "training_labels = training_labels.to_numpy()\n",
    "\n",
    "valid_data = full_pipeline.transform(valid_data).toarray()\n",
    "valid_labels = valid_labels.to_numpy()\n",
    "\n",
    "test_data = full_pipeline.transform(test_data).toarray()\n",
    "test_labels = test_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298805, 64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 7: Start training models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def build_weather_model(n_hidden=1, n_neurons=30, input_shape=[64]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_weather_model, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896413 samples, validate on 298805 samples\n",
      "Epoch 1/200\n",
      "896413/896413 [==============================] - 27s 30us/sample - loss: 4352.4849 - val_loss: 270.4751\n",
      "Epoch 2/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 79.6988 - val_loss: 108.8216\n",
      "Epoch 3/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 68.3160 - val_loss: 49.1093\n",
      "Epoch 4/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 63.4147 - val_loss: 41.1363\n",
      "Epoch 5/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 59.0751 - val_loss: 152.9370\n",
      "Epoch 6/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 56.1796 - val_loss: 42.5975\n",
      "Epoch 7/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 53.8283 - val_loss: 72.7457\n",
      "Epoch 8/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 52.0361 - val_loss: 59.3802\n",
      "Epoch 9/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 50.1079 - val_loss: 48.1819\n",
      "Epoch 10/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 49.7136 - val_loss: 32.2451\n",
      "Epoch 11/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 48.6899 - val_loss: 34.9485\n",
      "Epoch 12/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 46.5771 - val_loss: 38.7103\n",
      "Epoch 13/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 47.0473 - val_loss: 31.9002\n",
      "Epoch 14/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 46.4421 - val_loss: 51.3479\n",
      "Epoch 15/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 45.7015 - val_loss: 32.4471\n",
      "Epoch 16/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 45.1256 - val_loss: 39.0908\n",
      "Epoch 17/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 44.2306 - val_loss: 38.3238\n",
      "Epoch 18/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 43.6830 - val_loss: 53.2903\n",
      "Epoch 19/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 43.4114 - val_loss: 32.7661\n",
      "Epoch 20/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 42.6102 - val_loss: 32.7805\n",
      "Epoch 21/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 42.3203 - val_loss: 33.2434\n",
      "Epoch 22/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 41.9948 - val_loss: 33.2354\n",
      "Epoch 23/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 41.9925 - val_loss: 347.0174\n",
      "Epoch 24/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 41.6598 - val_loss: 31.6661\n",
      "Epoch 25/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 41.1535 - val_loss: 32.6004\n",
      "Epoch 26/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 40.5471 - val_loss: 33.3744\n",
      "Epoch 27/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 40.5502 - val_loss: 62.3625\n",
      "Epoch 28/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 40.3425 - val_loss: 60.6608\n",
      "Epoch 29/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 39.9506 - val_loss: 35.9755\n",
      "Epoch 30/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 39.9550 - val_loss: 51.3293\n",
      "Epoch 31/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 40.0575 - val_loss: 32.4877\n",
      "Epoch 32/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 39.6006 - val_loss: 33.1121\n",
      "Epoch 33/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 39.1367 - val_loss: 30.7784\n",
      "Epoch 34/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 39.3448 - val_loss: 35.9751\n",
      "Epoch 35/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 38.8332 - val_loss: 36.1707\n",
      "Epoch 36/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 38.6895 - val_loss: 32.8221\n",
      "Epoch 37/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 38.6061 - val_loss: 45.0068\n",
      "Epoch 38/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 38.3606 - val_loss: 31.1212\n",
      "Epoch 39/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 38.0552 - val_loss: 40.7890\n",
      "Epoch 40/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 38.0971 - val_loss: 31.1064\n",
      "Epoch 41/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 37.8191 - val_loss: 30.4417\n",
      "Epoch 42/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 37.6772 - val_loss: 36.2190\n",
      "Epoch 43/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 37.5834 - val_loss: 104.2192\n",
      "Epoch 44/200\n",
      "896413/896413 [==============================] - 26s 28us/sample - loss: 37.2117 - val_loss: 39.9432\n",
      "Epoch 45/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 37.1137 - val_loss: 37.8834\n",
      "Epoch 46/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 37.0475 - val_loss: 32.1746\n",
      "Epoch 47/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 37.0414 - val_loss: 99.3037\n",
      "Epoch 48/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 36.7661 - val_loss: 32.2175\n",
      "Epoch 49/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 36.6554 - val_loss: 32.5063\n",
      "Epoch 50/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 36.4741 - val_loss: 39.6355\n",
      "Epoch 51/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 36.3737 - val_loss: 30.8624\n",
      "Epoch 52/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 36.1690 - val_loss: 30.5441\n",
      "Epoch 53/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 35.9844 - val_loss: 31.0098\n",
      "Epoch 54/200\n",
      "896413/896413 [==============================] - 26s 28us/sample - loss: 36.0908 - val_loss: 34.0171\n",
      "Epoch 55/200\n",
      "896413/896413 [==============================] - 26s 28us/sample - loss: 35.7731 - val_loss: 35.9032\n",
      "Epoch 56/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 35.8760 - val_loss: 64.7721\n",
      "Epoch 57/200\n",
      "896413/896413 [==============================] - 26s 29us/sample - loss: 35.5753 - val_loss: 31.3096\n",
      "Epoch 58/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 35.4331 - val_loss: 31.4854\n",
      "Epoch 59/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 35.6131 - val_loss: 71.2386\n",
      "Epoch 60/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 35.7548 - val_loss: 42.0096\n",
      "Epoch 61/200\n",
      "896413/896413 [==============================] - 25s 28us/sample - loss: 35.3352 - val_loss: 33.0876\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = build_weather_model(n_hidden=10, n_neurons=100, input_shape=training_data.shape[1:])\n",
    "weather_model = model.fit(training_data, training_labels, epochs=200,\n",
    "                   batch_size=128, validation_data=(valid_data, valid_labels),\n",
    "                   callbacks=[keras.callbacks.EarlyStopping(patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398407/398407 [==============================] - 19s 47us/sample - loss: 36.1238\n"
     ]
    }
   ],
   "source": [
    "#n = 300, hidden = 5, loss = 1.3554\n",
    "#n = 500, hidden = 4, loss = 1.4676\n",
    "\n",
    "# pressure\n",
    "#n = 500, hidden = 5, loss = 33.8083\n",
    "# n = 250 performed slightly better prob around 30.0\n",
    "\n",
    "#n = 250, hidden = 10, loss = 33.8063\n",
    "#n = 100, hidden = 10, loss = 36.1238\n",
    "mse_test = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"temp_model.1.3554.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = temp_test_data[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[278.3897 ],\n",
       "       [287.9649 ],\n",
       "       [295.60535]], dtype=float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[279.17 ],\n",
       "       [286.218],\n",
       "       [296.13 ]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test_labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
